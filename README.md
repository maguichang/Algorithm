# Algorithm
## 常用算法note
## KNN k近邻算法
- 解决分类问题
- 天然可以解决多分类问题
- 思想简单，效果强大

缺点：

1.最大缺点：效率低下

如果训练集有m个样本，n个特征，则预测每一个新的数据，需要O(m*n)
解决方案：使用树结构，KD-tree

2.数据高度相关

3.预测结果不具有可解释性

4.维数灾难

随着维数的增加，看似相近的两个点之间的距离越来越大

维度 | 点 | 距离
---|---|---
1维 | 0到1的距离| 1
2维 | （0，0）到（1，1）的距离|1.414
3维 | （0，0，0）到（1，1，1）的距离| 1.73
64维  | （0，0，...0）到（1，1,...1）的距离|8
10000维| （0，0，...0）到（1，1,...1）的距离|100

## 降维技术 PCA（Principal Component Aanalysis,PCA）
通俗理解：就是找出一个最主要的特征，然后进行分析
- 使得数据集更容易使用
- 降低很多算法的计算开销
- 去除噪音
- 使得结果易懂
- 便于可视化

## 多项式回归PolynomialRegression

多项式回归本质上就是将一个特征的高次幂也作为特征来处理，
是对线性回归的改进

## 正则化的线性回归 —— 岭回归与Lasso回归

使用多项式回归，如果多项式最高次项比较大，模型就容易出现过拟合。正则化是一种常见的防止过拟合的方法，一般原理是在代价函数后面加上一个对参数的约束项，这个约束项被叫做正则化项（regularizer）。在线性回归模型中，通常有两种不同的正则化项：

- 加上所有参数（不包括θ0）的绝对值之和，即l1范数，此时叫做Lasso回归；
- 加上所有参数（不包括θ0）的平方和，即l2范数，此时叫做岭回归.
